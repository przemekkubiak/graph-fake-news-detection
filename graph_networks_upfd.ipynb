{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDveVew2lNzRfw2zfUhfV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/przemekkubiak/graph-fake-news-detection/blob/main/graph_networks_upfd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "wTMAzupc8MPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "Sez81uk8j19Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5abcb8-1d2d-4b2e-ec70-601beb0cbe81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-geometric  --y\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "EW0ALtK5yjd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cae2c38-a237-4d40-a554-d58e97342497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-ncp8p6e_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-ncp8p6e_\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 13d819819aa49e5661bee54258b233676bf25634\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.9.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.25.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (4.66.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.6.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.6.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.6.0) (3.3.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.6.0-py3-none-any.whl size=1100960 sha256=143dc32144ae8e0fb0929a9d2cf608b727653514e1a80ba8386f4f8c3db446cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g35arxfz/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "37rAm99QpvlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.datasets import UPFD\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch_geometric\n",
        "from torch_geometric.transforms import ToUndirected, NormalizeFeatures\n",
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, global_max_pool"
      ],
      "metadata": {
        "id": "PIyVTU4ljrZ_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to connect to Google Drive and mount at a specific directory within yout Google Drive. This can be used to load datasets not included in Python libraries and export data or metadata."
      ],
      "metadata": {
        "id": "Bw2oIATyTzS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPjsij2A2g4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3709a398-d9fe-4039-9119-ce6ae59b342a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aozusVI2v89",
        "outputId": "4baeeadc-e3d5-49c6-adfa-c909422d06ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/project_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMDm6uK-3GUM",
        "outputId": "f597b894-e698-4baa-845b-8c22f08ee06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/project_folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "4iwsrI1IiWyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FIS7edUBZQK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0xg0vykBZOfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, I am using the dataset proposed by [Dou et al. (2021)](https://arxiv.org/abs/2104.12259). This is a benchmark dataset made in line with the authors' proposed framework accounting for social information like user's preference. See the paper for details."
      ],
      "metadata": {
        "id": "1FH0SjGIYjPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = UPFD(root='data/', name = 'politifact', feature= 'spacy')\n",
        "\n",
        "# Get the first graph objects from the dataset.\n",
        "data = dataset[0]\n",
        "\n",
        "# Check the basic statistics of the graph.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')"
      ],
      "metadata": {
        "id": "SncSmOt2h50K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e240b2-dcb4-4de4-dff4-f789b955d854"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data(x=[72, 300], edge_index=[2, 71], y=[1])\n",
            "===========================================================================================================\n",
            "\n",
            "Dataset: UPFD(62, name=politifact, feature=spacy):\n",
            "======================\n",
            "Number of graphs: 62\n",
            "Number of features: 300\n",
            "Number of classes: 2\n",
            "Number of nodes: 72\n",
            "Number of edges: 71\n",
            "Average node degree: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training, validation, and test datasets. I use transform = ToUndirected() to enable the GNN to pass messages in both directions."
      ],
      "metadata": {
        "id": "8c9IjCgJVRqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = UPFD(root='data/', name = 'politifact', feature= 'spacy', split = 'train',transform = ToUndirected())\n",
        "val_dataset = UPFD(root='data/', name = 'politifact', feature= 'spacy', split = 'val', transform = ToUndirected())\n",
        "test_dataset = UPFD(root='data/', name = 'politifact', feature= 'spacy', split = 'test', transform = ToUndirected())"
      ],
      "metadata": {
        "id": "OuGnNNj2tiyA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilise the DataLoader class for mini-batching of the graph data. Generally, this helps fully utilise the GNU: with the memory overhead decreased, large graphs can fit into the GNU memory thanks to the procedure of saving adjacency matrices holding only non-zero entities. It also avoids the need of operators reliant on message passing to be modified as messages are no longer exchanged between nodes belonding to different graphs."
      ],
      "metadata": {
        "id": "DDeiChq3R-BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()"
      ],
      "metadata": {
        "id": "6lORznJHvLse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4880308-010d-4d58-bc57-373a5e30c190"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "DataBatch(x=[3013, 300], edge_index=[2, 5962], y=[32], batch=[3013], ptr=[33])\n",
            "\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 30\n",
            "DataBatch(x=[3059, 300], edge_index=[2, 6058], y=[30], batch=[3059], ptr=[31])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Kj7LBffXjLNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, define a network class for computation. Then, define training and testing functions. Both are slightly modified code from PyG's source code (see [Fey and Lenssen 2019](https://arxiv.org/abs/1903.02428) and the [GitHub](https://github.com/pyg-team/pytorch_geometric?tab=readme-ov-file))."
      ],
      "metadata": {
        "id": "oHR2khUUTD-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, model, in_channels, hidden_channels, out_channels,\n",
        "                 concat=False):\n",
        "        super().__init__()\n",
        "        self.concat = concat\n",
        "\n",
        "        if model == 'GCN':\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        elif model == 'SAGE':\n",
        "            self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        elif model == 'GAT':\n",
        "            self.conv1 = GATConv(in_channels, hidden_channels)\n",
        "\n",
        "        if self.concat:\n",
        "            self.lin0 = Linear(in_channels, hidden_channels)\n",
        "            self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin2 = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        h = self.conv1(x, edge_index).relu()\n",
        "        h = global_max_pool(h, batch)\n",
        "\n",
        "        if self.concat:\n",
        "            # Get the root node (tweet) features of each graph:\n",
        "            root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
        "            root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
        "            news = x[root]\n",
        "\n",
        "            news = self.lin0(news).relu()\n",
        "            h = self.lin1(torch.cat([news, h], dim=-1)).relu()\n",
        "\n",
        "        h = self.lin2(h)\n",
        "        return h.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "chosen_model = 'GCN'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(chosen_model, train_dataset.num_features, 128,\n",
        "            train_dataset.num_classes, concat=True).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_correct = total_examples = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        pred = model(data.x, data.edge_index, data.batch).argmax(dim=-1)\n",
        "        total_correct += int((pred == data.y).sum())\n",
        "        total_examples += data.num_graphs\n",
        "\n",
        "    return total_correct / total_examples\n",
        "\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    train_acc = test(train_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
        "          f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vhMHn6CvZXt",
        "outputId": "dab05bd8-2130-4501-b7c0-3bc7e4dc84c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 0.6850, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 02, Loss: 0.6827, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 03, Loss: 0.6741, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 04, Loss: 0.6713, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 05, Loss: 0.6678, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 06, Loss: 0.6646, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 07, Loss: 0.6631, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 08, Loss: 0.6581, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 09, Loss: 0.6555, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 10, Loss: 0.6482, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 11, Loss: 0.6416, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 12, Loss: 0.6397, Train: 0.5806, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 13, Loss: 0.6293, Train: 0.5968, Val: 0.4194, Test: 0.4887\n",
            "Epoch: 14, Loss: 0.6202, Train: 0.6290, Val: 0.4516, Test: 0.5249\n",
            "Epoch: 15, Loss: 0.6060, Train: 0.7581, Val: 0.5806, Test: 0.6063\n",
            "Epoch: 16, Loss: 0.5941, Train: 0.7903, Val: 0.6129, Test: 0.6697\n",
            "Epoch: 17, Loss: 0.5759, Train: 0.7903, Val: 0.5806, Test: 0.6561\n",
            "Epoch: 18, Loss: 0.5601, Train: 0.7742, Val: 0.5806, Test: 0.6199\n",
            "Epoch: 19, Loss: 0.5403, Train: 0.8387, Val: 0.6452, Test: 0.6878\n",
            "Epoch: 20, Loss: 0.5245, Train: 0.8871, Val: 0.7419, Test: 0.7873\n",
            "Epoch: 21, Loss: 0.4943, Train: 0.8871, Val: 0.6774, Test: 0.7602\n",
            "Epoch: 22, Loss: 0.4672, Train: 0.8871, Val: 0.5806, Test: 0.7421\n",
            "Epoch: 23, Loss: 0.4514, Train: 0.9194, Val: 0.7097, Test: 0.7828\n",
            "Epoch: 24, Loss: 0.4242, Train: 0.9032, Val: 0.7097, Test: 0.7647\n",
            "Epoch: 25, Loss: 0.3957, Train: 0.9032, Val: 0.7742, Test: 0.7738\n",
            "Epoch: 26, Loss: 0.3677, Train: 0.9194, Val: 0.8065, Test: 0.7919\n",
            "Epoch: 27, Loss: 0.3538, Train: 0.8871, Val: 0.7742, Test: 0.7919\n",
            "Epoch: 28, Loss: 0.3251, Train: 0.9355, Val: 0.7419, Test: 0.7783\n",
            "Epoch: 29, Loss: 0.3196, Train: 0.9355, Val: 0.7419, Test: 0.7783\n",
            "Epoch: 30, Loss: 0.2952, Train: 0.9032, Val: 0.7742, Test: 0.7919\n",
            "Epoch: 31, Loss: 0.2795, Train: 0.9677, Val: 0.8065, Test: 0.7964\n",
            "Epoch: 32, Loss: 0.2607, Train: 0.9355, Val: 0.7742, Test: 0.7828\n",
            "Epoch: 33, Loss: 0.2577, Train: 0.9516, Val: 0.7742, Test: 0.8009\n",
            "Epoch: 34, Loss: 0.2305, Train: 0.9839, Val: 0.8387, Test: 0.7964\n",
            "Epoch: 35, Loss: 0.2139, Train: 0.9839, Val: 0.8710, Test: 0.8054\n",
            "Epoch: 36, Loss: 0.2050, Train: 0.9839, Val: 0.8710, Test: 0.8009\n",
            "Epoch: 37, Loss: 0.1917, Train: 0.9839, Val: 0.8065, Test: 0.8100\n",
            "Epoch: 38, Loss: 0.1849, Train: 0.9839, Val: 0.8710, Test: 0.8100\n",
            "Epoch: 39, Loss: 0.1834, Train: 0.9839, Val: 0.8710, Test: 0.8100\n",
            "Epoch: 40, Loss: 0.1637, Train: 0.9839, Val: 0.8387, Test: 0.7873\n",
            "Epoch: 41, Loss: 0.1633, Train: 0.9839, Val: 0.8710, Test: 0.8100\n",
            "Epoch: 42, Loss: 0.1590, Train: 0.9839, Val: 0.8065, Test: 0.8235\n",
            "Epoch: 43, Loss: 0.1472, Train: 0.9839, Val: 0.8710, Test: 0.8054\n",
            "Epoch: 44, Loss: 0.1401, Train: 0.9839, Val: 0.8065, Test: 0.7964\n",
            "Epoch: 45, Loss: 0.1379, Train: 0.9839, Val: 0.8710, Test: 0.8190\n",
            "Epoch: 46, Loss: 0.1283, Train: 0.9839, Val: 0.8710, Test: 0.8416\n",
            "Epoch: 47, Loss: 0.1349, Train: 0.9839, Val: 0.8710, Test: 0.8100\n",
            "Epoch: 48, Loss: 0.1371, Train: 0.9839, Val: 0.7419, Test: 0.7919\n",
            "Epoch: 49, Loss: 0.1196, Train: 0.9839, Val: 0.8710, Test: 0.8416\n",
            "Epoch: 50, Loss: 0.1183, Train: 0.9839, Val: 0.8710, Test: 0.8507\n",
            "Epoch: 51, Loss: 0.1190, Train: 0.9839, Val: 0.8710, Test: 0.8054\n",
            "Epoch: 52, Loss: 0.1501, Train: 0.9839, Val: 0.7742, Test: 0.7964\n",
            "Epoch: 53, Loss: 0.1049, Train: 0.9839, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 54, Loss: 0.1191, Train: 0.9839, Val: 0.8710, Test: 0.8416\n",
            "Epoch: 55, Loss: 0.1081, Train: 0.9839, Val: 0.8065, Test: 0.8009\n",
            "Epoch: 56, Loss: 0.1024, Train: 0.9839, Val: 0.8387, Test: 0.8145\n",
            "Epoch: 57, Loss: 0.0932, Train: 0.9839, Val: 0.8710, Test: 0.8371\n",
            "Epoch: 58, Loss: 0.0990, Train: 0.9839, Val: 0.8710, Test: 0.8371\n",
            "Epoch: 59, Loss: 0.0932, Train: 0.9839, Val: 0.7742, Test: 0.8054\n",
            "Epoch: 60, Loss: 0.0953, Train: 0.9839, Val: 0.8065, Test: 0.8190\n",
            "Epoch: 61, Loss: 0.0869, Train: 0.9839, Val: 0.8710, Test: 0.8371\n",
            "Epoch: 62, Loss: 0.0908, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 63, Loss: 0.0871, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 64, Loss: 0.0858, Train: 1.0000, Val: 0.7742, Test: 0.8100\n",
            "Epoch: 65, Loss: 0.0860, Train: 0.9839, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 66, Loss: 0.0826, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 67, Loss: 0.0832, Train: 0.9839, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 68, Loss: 0.0810, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 69, Loss: 0.0832, Train: 1.0000, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 70, Loss: 0.0778, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 71, Loss: 0.0851, Train: 0.9839, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 72, Loss: 0.0798, Train: 1.0000, Val: 0.7419, Test: 0.8145\n",
            "Epoch: 73, Loss: 0.0841, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 74, Loss: 0.0785, Train: 0.9839, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 75, Loss: 0.0733, Train: 1.0000, Val: 0.7742, Test: 0.8281\n",
            "Epoch: 76, Loss: 0.0766, Train: 1.0000, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 77, Loss: 0.0810, Train: 0.9839, Val: 0.8387, Test: 0.8326\n",
            "Epoch: 78, Loss: 0.0766, Train: 1.0000, Val: 0.7419, Test: 0.8281\n",
            "Epoch: 79, Loss: 0.0735, Train: 1.0000, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 80, Loss: 0.0699, Train: 0.9839, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 81, Loss: 0.0699, Train: 1.0000, Val: 0.8065, Test: 0.8416\n",
            "Epoch: 82, Loss: 0.0682, Train: 1.0000, Val: 0.7742, Test: 0.8326\n",
            "Epoch: 83, Loss: 0.0690, Train: 1.0000, Val: 0.8387, Test: 0.8462\n",
            "Epoch: 84, Loss: 0.0676, Train: 1.0000, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 85, Loss: 0.0667, Train: 1.0000, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 86, Loss: 0.0660, Train: 1.0000, Val: 0.7742, Test: 0.8416\n",
            "Epoch: 87, Loss: 0.0671, Train: 1.0000, Val: 0.7742, Test: 0.8416\n",
            "Epoch: 88, Loss: 0.0650, Train: 1.0000, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 89, Loss: 0.0671, Train: 1.0000, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 90, Loss: 0.0658, Train: 1.0000, Val: 0.7742, Test: 0.8416\n",
            "Epoch: 91, Loss: 0.0659, Train: 1.0000, Val: 0.8387, Test: 0.8416\n",
            "Epoch: 92, Loss: 0.0641, Train: 1.0000, Val: 0.8387, Test: 0.8371\n",
            "Epoch: 93, Loss: 0.0646, Train: 1.0000, Val: 0.7742, Test: 0.8416\n",
            "Epoch: 94, Loss: 0.0669, Train: 1.0000, Val: 0.7419, Test: 0.8326\n",
            "Epoch: 95, Loss: 0.0620, Train: 0.9839, Val: 0.8065, Test: 0.8416\n",
            "Epoch: 96, Loss: 0.0662, Train: 1.0000, Val: 0.8065, Test: 0.8371\n",
            "Epoch: 97, Loss: 0.0684, Train: 1.0000, Val: 0.8065, Test: 0.8371\n",
            "Epoch: 98, Loss: 0.0587, Train: 1.0000, Val: 0.8065, Test: 0.8371\n",
            "Epoch: 99, Loss: 0.0650, Train: 1.0000, Val: 0.8065, Test: 0.8416\n",
            "Epoch: 100, Loss: 0.0657, Train: 1.0000, Val: 0.7419, Test: 0.8371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "089raj_HwaG9",
        "outputId": "4f36e903-2390-4d87-c501-a6c8ba496e84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8371040723981901"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8sBmq3lw_FW",
        "outputId": "ed34ebed-8b69-4aa3-fe73-9efb2dd0a6ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): GCNConv(300, 128)\n",
            "  (lin0): Linear(in_features=300, out_features=128, bias=True)\n",
            "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (lin2): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}